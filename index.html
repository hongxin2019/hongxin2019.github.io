<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Xin Hong</title><meta name="gridsome:hash" content="41f870b211e0d0fbacb120db264b4b2fcdba33d3"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.23"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><meta data-vue-tag="ssr" name="viewport" content="width=device-width, initial-scale=1"><meta data-vue-tag="ssr" data-key="description" name="description" content="I am currently a Postdoc of Computer Science and Technology at Institute for AI Industry Research (AIR), Tsinghua University, working with Weiying Ma and Yanyan Lan. Before joining AIR, I finished my PhD at Institute of Computing Technology (ICT), Chinese Academy of Sciences, advised by Shuo Bai and Yanyan Lan. I also had internships at Beijing Academy of Artificial Intelligence (BAAI), working with Team WuDao-WenLan, and at Megvii Research, working with Pengfei Xiong and Haoqiang Fan.
"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/assets/static/favicon.b9532cc.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/assets/static/favicon.f22e9f3.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="152x152" href="/assets/static/favicon.62d22cb.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="120x120" href="/assets/static/favicon.1539b60.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="167x167" href="/assets/static/favicon.dc0cdc5.c2b8cefdf66036f009cfe6d53904105f.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="180x180" href="/assets/static/favicon.7b22250.c2b8cefdf66036f009cfe6d53904105f.png"><link rel="preload" href="/assets/css/0.styles.40765d7f.css" as="style"><link rel="preload" href="/assets/js/app.ee5d2fef.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--people-vue.784e621e.js" as="script"><link rel="preload" href="/assets/js/vue-remark--content--people--me-md.c00dfe80.js" as="script"><link rel="prefetch" href="/assets/js/page--node-modules--gridsome--app--pages--404-vue.2c2d24a1.js"><link rel="stylesheet" href="/assets/css/0.styles.40765d7f.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
  </head>
  <body >
    <div data-server-rendered="true" id="app" class="text-sm" style="line-height:normal;"><div class="min-h-screen"><div id="banner" class="h-12 w-full text-lg fixed top-0 shadow"><div class="md:max-w-5xl px-4 flex justify-between mx-auto items-center h-full"><div class="font-bold">Xin Hong</div><div class="flex gap-2 md:gap-8"><a class="text-base cursor-pointer">Home</a><a class="text-base cursor-pointer">Publications</a><a class="text-base cursor-pointer">Projects</a></div></div></div><div id="info" class="max-w-5xl mx-auto text-base mt-16 pt-4 px-4 flex flex-wrap gap-4 md:gap-16 h-full"><div><img src="/image/hongxin.jpg" class="w-48"></div><div class="flex flex-col leading-6 mt-4"><div class="text-3xl font-bold mb-5"><span>Xin Hong</span><span>
          「洪鑫」
        </span></div><div>
        Postdoc
      </div><div>
        Institute for AI Industry Research (AIR)
      </div><div>
        Tsinghua University
      </div><div>
        Email: hongxin [at] air (dot) tsinghua (dot) edu (dot) cn
      </div><div class="mt-4 flex"><div class="flex"><div class="text-blue-700"><a href="https://scholar.google.com/citations?user=gW-9WOQAAAAJ&amp;hl=en" target="_blank">Google Scholar</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/" target="_blank">Github</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://www.semanticscholar.org/author/Xin-Hong/145251362" target="_blank">Semantic Scholar</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="/pdf/hongxin_cv.pdf" target="_blank">CV</a></div><!----></div></div></div><div class="mt-4 md:mt-8 leading-6"><div class="font-bold">Current Research Topics:</div><ul class="list-disc list-inside mt-1"><li class="ml-2">
          AI4Science
        </li><li class="ml-2">
          Multimodal Learning
        </li></ul></div></div><div class="max-w-5xl text-base mx-auto leading-6 mt-4 people px-4"><div><p>I am currently a Postdoc of Computer Science and Technology at <a href="https://air.tsinghua.edu.cn/info/1007/2127.htm" target="_blank" rel="nofollow noopener noreferrer">Institute for AI Industry Research (AIR)</a>, Tsinghua University, working with <a href="https://air.tsinghua.edu.cn/en/info/1046/1189.htm" target="_blank" rel="nofollow noopener noreferrer">Weiying Ma</a> and <a href="https://yanyanlan.com" target="_blank" rel="nofollow noopener noreferrer">Yanyan Lan</a>. Before joining AIR, I finished my PhD at <a href="http://www.ict.ac.cn/" target="_blank" rel="nofollow noopener noreferrer">Institute of Computing Technology (ICT)</a>, Chinese Academy of Sciences, advised by <a href="http://www.ict.cas.cn/sourcedb_2018_ict_cas/cn/jssrck/200909/t20090917_2496582.html" target="_blank" rel="nofollow noopener noreferrer">Shuo Bai</a> and <a href="https://yanyanlan.com" target="_blank" rel="nofollow noopener noreferrer">Yanyan Lan</a>. I also had internships at Beijing Academy of Artificial Intelligence (BAAI), working with Team WuDao-WenLan, and at Megvii Research, working with <a href="https://scholar.google.com/citations?user=ctLbu3IAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="nofollow noopener noreferrer">Pengfei Xiong</a> and <a href="https://scholar.google.com/citations?hl=en&amp;user=bzzBut4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="nofollow noopener noreferrer">Haoqiang Fan</a>.</p><p>My current primary research interest lies in exploring problems in the field of life sciences using deep learning tools, particularly in topics such as <a href="https://yanyanlan.com/project/airfold/" target="_blank" rel="nofollow noopener noreferrer">protein structure prediction</a>, interactions, protein design, etc. Additionally, I am continuously keeping track of research related to multimodal learning and <a href="https://github.com/hughplay/Visual-Reasoning-Papers" target="_blank" rel="nofollow noopener noreferrer">visual reasoning</a>.</p></div></div><div class="max-w-5xl text-base mx-auto leading-6 mt-8 px-4"><div id="publications" class="text-lg font-bold mb-2"><span>Publications</span></div></div><div class="max-w-5xl text-base mx-auto leading-6 mt-8 px-4"><div id="projects" class="text-lg font-bold mb-5">Projects</div><div class="md:flex gap-4 mb-8 md:mb-5"><div class="w-full md:w-64 flex-none"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="w-full v-lazy-image"></div><div class="mt-2 md:mt-0 flex flex-col shrink"><div class="font-bold">AIRFold</div><div class="italic"></div><div class="flex text-gray-600 flex-wrap"><div><a href="https://bowen-gao.github.io/" target="_blank" class="hover:underline text-gray-600">Xin Hong</a><span class="pr-2">,</span></div><div><a href="https://scholar.google.com/citations?user=MayCLqYAAAAJ&amp;hl=en" target="_blank" class="hover:underline text-gray-600">Jingjing Gong</a><span class="pr-2">,</span></div><div><a href="https://yuxuansong.com/" target="_blank" class="hover:underline text-gray-600">Yuxuan Song</a><span class="pr-2">,</span></div><div><a href="https://www.semanticscholar.org/author/Yinjun-Jia/145105686" target="_blank" class="hover:underline text-gray-600">Yinjun Jia</a><span class="pr-2">,</span></div><div><span>Keyue Qiu</span><span class="pr-2">,</span></div><div><span>Han Tang</span><span class="pr-2">,</span></div><div><a href="https://github.com/thchuan2001" target="_blank" class="hover:underline text-gray-600">Haichuan Tan</a><span class="pr-2">,</span></div><div><span>Yanyan Lan</span><!----></div></div><div class="flex"><div class="flex"><div class="text-blue-700"><a href="https://yanyanlan.com/project/airfold" target="_blank">Project Page</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://air.tsinghua.edu.cn/info/1007/1807.htm" target="_blank">Official News</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://www.qbitai.com/2022/09/37783.html" target="_blank">QbitAI Interview</a></div><!----></div></div><div class="flex flex-col text-red-700 font-bold"><div class="flex"><div><a href="https://www.cameo3d.org/modeling/targets/1-month/?to_date=2022-08-20" target="_blank">Ranked first in the CAMEO 3D Structure Prediction Challenge</a></div></div></div></div></div><div class="md:flex gap-4 mb-8 md:mb-5"><div class="w-full md:w-64 flex-none"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="w-full v-lazy-image"></div><div class="mt-2 md:mt-0 flex flex-col shrink"><div class="font-bold">Microservices Demo</div><div class="italic">A microservices demo built with celery and fastapi.</div><!----><div class="flex"><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/celery_fastapi_demo?tab=readme-ov-file#quick-start" target="_blank">Quick Start</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/celery_fastapi_demo" target="_blank">Source Code</a></div><!----></div></div><div class="flex flex-col text-red-700 font-bold"></div></div></div><div class="md:flex gap-4 mb-8 md:mb-5"><div class="w-full md:w-64 flex-none"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="w-full v-lazy-image"></div><div class="mt-2 md:mt-0 flex flex-col shrink"><div class="font-bold">DeepCodebase</div><div class="italic">DeepCodebase is a project template for deep learning researchers, on purpose of improving the efficiency of experiments and open source.</div><!----><div class="flex"><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/DeepCodebase?tab=readme-ov-file#quick-start" target="_blank">Quick Start</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/DeepCodebase" target="_blank">Source Code</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/DeepCodebase/generate" target="_blank">Use This Template</a></div><!----></div></div><div class="flex flex-col text-red-700 font-bold"></div></div></div><div class="md:flex gap-4 mb-8 md:mb-5"><div class="w-full md:w-64 flex-none"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="w-full v-lazy-image"></div><div class="mt-2 md:mt-0 flex flex-col shrink"><div class="font-bold">DockerLab</div><div class="italic">DockerLab helps you to build a docker container as your workspace.</div><!----><div class="flex"><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/dockerlab?tab=readme-ov-file#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B" target="_blank">Quick Start</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/dockerlab" target="_blank">Source Code</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/dockerlab/tree/main/dockerlab/templates" target="_blank">Prebuilt Image List</a></div><!----></div></div><div class="flex flex-col text-red-700 font-bold"></div></div></div><div class="md:flex gap-4 mb-8 md:mb-5"><div class="w-full md:w-64 flex-none"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="w-full v-lazy-image"></div><div class="mt-2 md:mt-0 flex flex-col shrink"><div class="font-bold">Tactic Board</div><div class="italic">A tactical board on your device for badminton, soccer, and basketball.</div><!----><div class="flex"><div class="flex"><div class="text-blue-700"><a href="https://tacticalboard.github.io/" target="_blank">Homepage</a></div><div class="mx-1">/</div></div><div class="flex"><div class="text-blue-700"><a href="https://github.com/hughplay/DeepCodebase" target="_blank">Source Code</a></div><!----></div></div><div class="flex flex-col text-red-700 font-bold"></div></div></div></div><div class="max-w-5xl text-base mx-auto leading-6 mt-8"></div><div id="counter-wrap" class="py-16 w-64 mx-auto"></div></div></div>
    <script>window.__INITIAL_STATE__={"data":{"people":{"name":"Xin Hong","name_cn":"洪鑫","excerpt":"I am currently a Postdoc of Computer Science and Technology at Institute for AI Industry Research (AIR), Tsinghua University, working with Weiying Ma and Yanyan Lan. Before joining AIR, I finished my PhD at Institute of Computing Technology (ICT), Chinese Academy of Sciences, advised by Shuo Bai and Yanyan Lan. I also had internships at Beijing Academy of Artificial Intelligence (BAAI), working with Team WuDao-WenLan, and at Megvii Research, working with Pengfei Xiong and Haoqiang Fan.\n","photo":"\u002Fimage\u002Fhongxin.jpg","topics":["AI4Science","Multimodal Learning"],"affiliation":["Postdoc","Institute for AI Industry Research (AIR)","Tsinghua University","Email: hongxin [at] air (dot) tsinghua (dot) edu (dot) cn"],"links":[{"name":"Google Scholar","link":"https:\u002F\u002Fscholar.google.com\u002Fcitations?user=gW-9WOQAAAAJ&hl=en"},{"name":"Github","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002F"},{"name":"Semantic Scholar","link":"https:\u002F\u002Fwww.semanticscholar.org\u002Fauthor\u002FXin-Hong\u002F145251362"},{"name":"CV","link":"\u002Fpdf\u002Fhongxin_cv.pdf"}],"publications":[{"title":"Visual Transformation Reasoning","selected":null,"topic":["Visual Reasoning"],"figure":"\u002Fimage\u002Fict-logo.png","authors":[],"venue":{"name":"PhD Thesis","year":2023,"link":""},"links":[{"name":"Thesis (in Chinese)","link":"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1MoFfITNof1XQ7cfhzrhbg1jRdXgKM_ee\u002Fview?usp=sharing"},{"name":"Slides (in Chinese)","link":"https:\u002F\u002Fdrive.google.com\u002Ffile\u002Fd\u002F1CCVCDQqF9949lrU2ox7j8cicKtrxnSqE\u002Fview?usp=sharing"}],"highlights":[]},{"title":"Visual Transformation Telling","selected":true,"topic":["Visual Reasoning"],"figure":"\u002Fimage\u002Fvtt.png","authors":[{"name":"Xin Hong","link":"https:\u002F\u002Fhongxin2019.github.io\u002F"},{"name":"Yanyan Lan","link":"https:\u002F\u002Fyanyanlan.com"},{"name":"Liang Pang","link":"https:\u002F\u002Fpl8787.github.io\u002F"},{"name":"Jiafeng Guo","link":"http:\u002F\u002Fwww.bigdatalab.ac.cn\u002Fgjf\u002F"},{"name":"Xueqi Cheng","link":""}],"venue":{"name":"arXiv","year":2023,"link":""},"links":[{"name":"Paper","link":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.01928.pdf"}],"highlights":[]},{"title":"Visual Reasoning: from State to Transformation","selected":true,"topic":["Visual Reasoning"],"figure":"\u002Fimage\u002Ftvr_illustration.png","authors":[{"name":"Xin Hong","link":"https:\u002F\u002Fhongxin2019.github.io\u002F"},{"name":"Yanyan Lan","link":"https:\u002F\u002Fyanyanlan.com"},{"name":"Liang Pang","link":"https:\u002F\u002Fpl8787.github.io\u002F"},{"name":"Jiafeng Guo","link":"http:\u002F\u002Fwww.bigdatalab.ac.cn\u002Fgjf\u002F"},{"name":"Xueqi Cheng","link":""}],"venue":{"name":"TPAMI","year":2023,"link":"https:\u002F\u002Fieeexplore.ieee.org\u002Fabstract\u002Fdocument\u002F10105523"},"links":[{"name":"Paper","link":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2305.01668.pdf"}],"highlights":[]},{"title":"Transformation Driven Visual Reasoning","selected":true,"topic":["Visual Reasoning"],"figure":"\u002Fimage\u002Ftvr.png","authors":[{"name":"Xin Hong","link":"https:\u002F\u002Fhongxin2019.github.io\u002F"},{"name":"Yanyan Lan","link":"https:\u002F\u002Fyanyanlan.com"},{"name":"Liang Pang","link":"https:\u002F\u002Fpl8787.github.io\u002F"},{"name":"Jiafeng Guo","link":"http:\u002F\u002Fwww.bigdatalab.ac.cn\u002Fgjf\u002F"},{"name":"Xueqi Cheng","link":""}],"venue":{"name":"CVPR","year":2021,"link":""},"links":[{"name":"Paper","link":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2011.13160.pdf"},{"name":"Code","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002FTVR"},{"name":"Homepage","link":"https:\u002F\u002Fhongxin2019.github.io\u002FTVR"},{"name":"Dataset","link":"https:\u002F\u002Fhongxin2019.github.io\u002FTVR\u002Fdataset"}],"highlights":[]},{"title":"WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-training","selected":true,"topic":["Multi-modal Learning"],"figure":"\u002Fimage\u002Fwenlan.png","authors":[{"name":"Yuqi Huo","link":""},{"name":"Manli Zhang","link":""},{"name":"Guangzhen Liu","link":""},{"name":"Haoyu Lu","link":""},{"name":"Yizhao Gao","link":""},{"name":"Guoxing Yang","link":""},{"name":"Jingyuan Wen","link":""},{"name":"Heng Zhang","link":""},{"name":"Baogui Xu","link":""},{"name":"Weihao Zheng","link":""},{"name":"Zongzheng Xi","link":""},{"name":"Yueqian Yang","link":""},{"name":"Anwen Hu","link":""},{"name":"Jinming Zhao","link":""},{"name":"Ruichen Li","link":""},{"name":"Yida Zhao","link":""},{"name":"Liang Zhang","link":""},{"name":"Yuqing Song","link":""},{"name":"Xin Hong","link":""},{"name":"Wanqing Cui","link":""},{"name":"Danyang Hou","link":""},{"name":"Yingyan Li","link":""},{"name":"Junyi Li","link":""},{"name":"Peiyu Liu","link":""},{"name":"Zheng Gong","link":""},{"name":"Chuhao Jin","link":""},{"name":"Yuchong Sun","link":""},{"name":"Shizhe Chen","link":""},{"name":"Zhiwu Lu","link":""},{"name":"Zhicheng Dou","link":""},{"name":"Qin Jin","link":""},{"name":"Yanyan Lan","link":""},{"name":"Wayne Xin Zhao","link":""},{"name":"Ruihua Song","link":""},{"name":"Ji-Rong Wen","link":""}],"venue":{"name":"arXiv","year":2021,"link":"https:\u002F\u002Farxiv.org\u002Fabs\u002F2103.06561"},"links":[{"name":"Paper","link":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2103.06561.pdf"},{"name":"Code","link":""}],"highlights":[{"name":"","link":""}]},{"title":"Deep Fusion Network for Image Completion","selected":null,"topic":["inpainting"],"figure":"\u002Fimage\u002Fdfnet.jpg","authors":[{"name":"Xin Hong","link":""},{"name":"Pengfei Xiong","link":""},{"name":"Renhe Ji","link":""},{"name":"Haoqiang Fan","link":""}],"venue":{"name":"ACMMM","year":2019,"link":""},"links":[{"name":"Paper","link":"\u002Fpdf\u002Fmm-2019-dfnet.pdf"},{"name":"Code","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002FDFNet"},{"name":"Demo","link":"https:\u002F\u002Fcolab.research.google.com\u002Fgithub\u002Fhughplay\u002FDFNet\u002Fblob\u002Fmaster\u002Fdemo.ipynb"}],"highlights":[{"name":"","link":""}]},{"title":"Attention-driven Factor Model for Explainable Personalized Recommendation","selected":null,"topic":["Recommendation System"],"figure":"\u002Fimage\u002Fafm.png","authors":[{"name":"Jingwu Chen","link":""},{"name":"Fuzhen Zhuang","link":""},{"name":"Xin Hong","link":""},{"name":"Xiang Ao","link":""},{"name":"Xing Xie","link":""},{"name":"Qing He","link":""}],"venue":{"name":"SIGIR","year":2018,"link":""},"links":[{"name":"Paper","link":"\u002Fpdf\u002Fsigir-2018-afm.pdf"}],"highlights":[{"name":"","link":""}]}],"projects":[{"title":"AIRFold","figure":"\u002Fimage\u002F7TVI.png","brief":"","authors":[{"name":"Xin Hong","link":"https:\u002F\u002Fbowen-gao.github.io\u002F"},{"name":"Jingjing Gong","link":"https:\u002F\u002Fscholar.google.com\u002Fcitations?user=MayCLqYAAAAJ&hl=en"},{"name":"Yuxuan Song","link":"https:\u002F\u002Fyuxuansong.com\u002F"},{"name":"Yinjun Jia","link":"https:\u002F\u002Fwww.semanticscholar.org\u002Fauthor\u002FYinjun-Jia\u002F145105686"},{"name":"Keyue Qiu","link":""},{"name":"Han Tang","link":""},{"name":"Haichuan Tan","link":"https:\u002F\u002Fgithub.com\u002Fthchuan2001"},{"name":"Yanyan Lan","link":""}],"links":[{"name":"Project Page","link":"https:\u002F\u002Fyanyanlan.com\u002Fproject\u002Fairfold"},{"name":"Official News","link":"https:\u002F\u002Fair.tsinghua.edu.cn\u002Finfo\u002F1007\u002F1807.htm"},{"name":"QbitAI Interview","link":"https:\u002F\u002Fwww.qbitai.com\u002F2022\u002F09\u002F37783.html"}],"highlights":[{"name":"Ranked first in the CAMEO 3D Structure Prediction Challenge","link":"https:\u002F\u002Fwww.cameo3d.org\u002Fmodeling\u002Ftargets\u002F1-month\u002F?to_date=2022-08-20"}]},{"title":"Microservices Demo","figure":"https:\u002F\u002Fraw.githubusercontent.com\u002Fhughplay\u002Fcelery_fastapi_demo\u002Fmaster\u002Fdemo.svg","brief":"A microservices demo built with celery and fastapi.","authors":[{"name":"Xin Hong","link":""}],"links":[{"name":"Quick Start","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002Fcelery_fastapi_demo?tab=readme-ov-file#quick-start"},{"name":"Source Code","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002Fcelery_fastapi_demo"}],"highlights":[]},{"title":"DeepCodebase","figure":"\u002Fimage\u002Fdeepcodebase_overview.png","brief":"DeepCodebase is a project template for deep learning researchers, on purpose of improving the efficiency of experiments and open source.","authors":[{"name":"Xin Hong","link":""}],"links":[{"name":"Quick Start","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002FDeepCodebase?tab=readme-ov-file#quick-start"},{"name":"Source Code","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002FDeepCodebase"},{"name":"Use This Template","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002FDeepCodebase\u002Fgenerate"}],"highlights":[]},{"title":"DockerLab","figure":"\u002Fimage\u002Fdockerlab.png","brief":"DockerLab helps you to build a docker container as your workspace.","authors":[{"name":"Xin Hong","link":""}],"links":[{"name":"Quick Start","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002Fdockerlab?tab=readme-ov-file#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"},{"name":"Source Code","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002Fdockerlab"},{"name":"Prebuilt Image List","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002Fdockerlab\u002Ftree\u002Fmain\u002Fdockerlab\u002Ftemplates"}],"highlights":[]},{"title":"Tactic Board","figure":"\u002Fimage\u002Fshuttle.jpg","brief":"A tactical board on your device for badminton, soccer, and basketball.","authors":[{"name":"Xin Hong","link":""}],"links":[{"name":"Homepage","link":"https:\u002F\u002Ftacticalboard.github.io\u002F"},{"name":"Source Code","link":"https:\u002F\u002Fgithub.com\u002Fhughplay\u002FDeepCodebase"}],"highlights":[]}]}},"context":{}};(function(){var s;(s=document.currentScript||document.scripts[document.scripts.length-1]).parentNode.removeChild(s);}());</script><script src="/assets/js/app.ee5d2fef.js" defer></script><script src="/assets/js/page--src--templates--people-vue.784e621e.js" defer></script><script src="/assets/js/vue-remark--content--people--me-md.c00dfe80.js" defer></script>
  </body>
</html>
